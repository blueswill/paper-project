\documentclass[utf8]{ctexart}
\usepackage{amsmath}
\usepackage{array}
\usepackage[a4paper, left=2.3cm, right=2.3cm]{geometry}
\begin{document}
\begin{abstract}
这篇论文描述了一个人脸识别系统. 它能够在达到极高检测速率的同时非常快速的处理图像. 这个架构有三个关键因素. 
第一, 我们引入了一个被称为“积分图”的新的图像表达方式. 利用它我们能够非常快地计算出检测器需要的图像特征. 
第二, 使用 AdaBoost 学习算法 (Freund and Schapire, 1995) 构建出的简单高效的分类器. 它能在非常大的潜在特征集合中选取少量重要可视化特征. 
第三, 我们采用级联分类器的方法快速去除图像的背景, 将更多的计算投入到识别面部特征上. 
我们已经在面部识别领域进行了一系列的实验. 和之前最好的系统 (Sung and Pollio, 1998; Rowley et al., 1998; Scheneiderman and Kanade, 2000; Roth el al., 2000) 相比, 这个系统在面部识别的表现上略逊一筹. 在传统电脑上的实现面部识别速率能够达到每秒 15 帧. 
关键字：面部识别, 加速, 人类感知
\end{abstract}
\section{Introduction}
这篇论文使用新的算法和视野构建了一个稳健而快速的视觉识别系统. 在这个基础上, 我们已经完成一个正脸识别系统. 它在识别率和错误率上已经达到了之前发布的最好结果 (Sung and Poggio, 1998; Rowley et al., 1998; Osuna et al., 1997a; Schneiderman and Kanade, 2000; Roth et al., 2000). 
不同于之前的那些, 这个系统能够非常快速地识别人脸. 在$384\times288$像素的图像以及700 MHz,  Intel Pentium III的传统电脑上, 面部识别的速率达到了每秒 15 帧. 
其他的面部识别系统使用了多个辅助信息来达到极高的速度, 例如视频序列中的图像差异以及图片中像素的颜色. 而我们的系统仅仅使用了单张灰度图像中的信息. 那些辅助信息仍然能够帮助我们达到更高的帧速. 
在我们的面部识别系统中有三个主要贡献. 下文将进行简短介绍. 在其他章节中我们将详细描述它们. 
这篇论文的第一个贡献是被称为“积分图 (integral image)”的新型图像表达方式. 它能够帮助我们快速地进行特征评价. 受到 Papageorgiou et al. (1998) 的工作的鼓舞, 我们的检测系统不直接工作在图像明暗度上. 
和之前的作者一样, 我们采用类似于哈尔基函数的一个特征集合. 我们也使用比哈尔基过滤更加复杂的过滤方式. 为了能够在多个尺寸上快速计算图像特征, 我们引入了积分图这一表达形式, 非常类似于计算机图形学中纹理贴图采用的积分图 (Crow, 1984). 
只要对图像中每个像素进行若干操作便能计算出其积分图. 一旦计算出积分图, 我们便能在常数时间内计算出任何尺寸任何地方的 Haar-like 特征. 

这篇论文的第二个贡献是实现了一个简单高效的分类器. 该分类器采用 AdaBoost 算法 (Freund and Schapire, 1995), 能够从大量的潜在特征集合中选择少量重要特征. 在图像的任何子区域 (sub-window)内 Haar-like 特征的数量远远超过了像素的数量. 
为了保证分类速度, 学习过程中我们必须去掉非常多的特征, 将精力集中在小部分重要特征上. 受到 Tieu 和 Viola 工作 (2000) 的启发, 我们通过限制每一个弱分类器到单一特征, 采用 AdaBoost 学习算法达到了我们的目的. 最终在增长过程中的每个阶段, 弱分类器的选择过程就可以看作是特征的选择过程.  AdaBoost 在提供高效算法的同时也对一般情况下的性能进行了强有力的约束 (Schapire et al., 1998). 

这篇论文的第三个主要贡献是提供了将更多分类器连接成级联结构的一种方法. 它通过关注图像的可行区域极大地提高了检测速度. 这个想法来源于如下论断：快速判断人脸将出现在图像地哪一部分通常是可行的 (Tsotsos et al., 1995; Itti et al., 1998; Amit and Geman, 1999; Fleuret and Geman, 2001). 
只有那些可行区域才值得进行更多复杂的处理流程. 一个关键参数是认知过程 (attentional process)的漏报率. 认知器 (attentional filter)必须能够识别出几乎所有的人脸. 

我们将描述训练一个简单高效的分类器流程, 它将用于监督式的认知操作 (attention operator). 一个面部检测认知操作在很大的数据集上可以达到过滤 50\% 的图像并保留 99\% 的面部的最终效果. 
这个过滤器也是非常高效. 它能在图像的每个地方执行 20 次操作, 总计大约 60 个微处理器指令. 

那些没有被最初的分类器拒绝的区域将被接下去的一系列分类器处理, 每一个都将比前一个略微得复杂一点. 如果其中一个区域被某个分类器拒绝, 那么它便不会再被继续处理. 这个级联检测流程的结构就是一个蜕化决策树 (degenerate decision tree), 这个工作和 Fleuret 和 Geman 的工作 (2001) 以及 Amit 和 Geman 的工作 (1999) 有关. 

一个完整的面部识别级联结构有 38 个分类器, 将近 80000 个操作. 这个级联结构仍然能达到非常快的平均检测速度. 在一个困难的数据集上, 其中包含 507 张脸, 75000000 个子区域, 识别的过程中平均每一个子区域使用了 270 个微处理器指令. 作为对比, 这个系统比 Rowley et al. (1998) 实现的识别系统快了将近 15 倍. 

一个极端快速的人脸识别器有着广阔的应用前景, 包括人机交互接口, 图像数据库以及电视会议. 速度上的提升将使那些实时的面部识别应用系统成为可能. 在那些不需要高帧速的应用中, 重要的后期处理和分析也将变得可行. 
另外, 我们的系统能够在大量小功率设备上实现, 比如手持设备以及嵌入式处理器等. 在实验室中, 我们在一台小功率 200mips Strong Arm 处理器上实现了这个面部识别系统. 这个处理器没有浮点运算硬件, 但是我们的系统仍然达到了每秒两帧的速度. 
\subsection{Overview}
论文接下去的章节将讨论检测器的实现, 相关的理论以及实验. 
第二章节将详细描述特征的形式以及快速计算的方法. 第三章节将讨论将这些特征结合在一起形成分类器的方法. 作为 AdaBoost 算法的一个应用, 机器学习也表现为特征选取机制. 尽管用这种方式完成的分类器有着良好的计算和分类性能, 但是作为实时分类器, 它们还是不够快. 
第四章节将描述级联分类器的方法. 最终形成一个快速高效的面部识别器. 第五章节将详述多个测试结果以及我们采取的实验方法. 最后, 第六章节对这个系统和其他相关系统之间关系进行了讨论. 
\section{Features}
我们的面部识别过程利用简单特征的值分类图像. 使用特征而不是直接用像素有着很多的优势. 最为常见的一点就是能够编码用有限的训练集很难学习的临时领域知识. 对于这个系统, 还有另外一点优势：基于特征的系统比基于像素的系统运行得更快. 

这种简单特征令人想起 Papageorgiou et al. (1998) 中使用的哈尔基函数 (haar basis function). 更专业地说, 我们使用了三种特征. 2-矩形特征 (two-rectangle feature) 的值是两个矩形区域像素和的差. 这两个区域有相同的大小和形状, 并且水平或者竖直相邻. (fig)
一个 3-矩形特征 (three-rectangle feature) 由两边矩形的和减去中间矩形的和而得. 最后一个 4-矩形特征 (four-rectangle feature) 由对角矩形和之差求得. 

假设检测器的初始分辨率为 $24\times24$, 矩形特征的整个集合大小为 160000. 注意到这个集合不像哈尔基 (haar basis), 是过完备 (overcomplete)的.

\subsection{积分图}

利用我们引入的图像中间表达方式---积分图, 矩形特征能够非常迅速的计算出来. 在 $(x, y)$ 处的积分图包含了在该点上方和左方的像素点的和, 用公式来说就是：
\[
    ii(x, y)= \sum_{x'\leq x, y'\leq y} i(x', y')
\]

其中 $ii(x, y)$ 表示积分图, 而 $i(x, y)$ 表示原始图. 使用如下的递归式：
\[
    \begin{array}{r@{}>{{}}l@{\qquad}r@{}>{{}}l}
        s(x,y)&=s(x,y-1)+i(x,y)\\
        ii(x,y)&=ii(x-1,y)+s(x,y)
    \end{array}
\]

其中 $s(x, y)$ 表示行的累和, 初始条件为$s(x,-1)=0, ii(-1,y)=0$. 只要遍历一遍整张图, 积分图便能计算出来. 

通过积分图, 任何矩形和可以通过四个数组引用计算出来. 很显然, 两个矩形的差值能够通过八个引用计算出来. 既然 2-矩形特征通过相邻的矩形定义, 它便能用六个数组引用计算出来, 同理 3-矩形特征用了八个数组引用, 4-矩形特征用了九个数组引用.

积分图的另一个来源是 Simard et al. (1999) 的工作. 这个工作的作者指出在线性运算中 (例如 $f\ast g$), 任何可逆线性运算可以施加于$f$或$g$上, 只要其逆运算一同施加于线性运算的结果之上. 例如在图像的卷积中, 如果微分运算施加于图形其卷积核上, 那么卷积结果必须通过二重积分运算才能和原式相等:
\[
    f\ast g = \iint(f'\ast g')
\]
若$f$和$g$的微分结果是稀疏的或者能够让它变得稀疏, 那么卷积的速度便能大大加快. 另外一个相似的观点就是线性运算和其逆运算分别施加于$f$和$g$上, 结果仍然不变:
\[
    (f'')\ast\iint g = f\ast g
\]
在我们系统中采用的矩形和的计算能够抽象为点积运算, $i\cdot r$, 其中$i$表示图像而$r$表示一个盒函数 (box car image, 感兴趣的矩形区域为$1$, 其他区域为$0$). 该运算又可写为:
\[
    i\cdot r = (\iint i)\cdot r''
\]
事实上该式中的双重积分就是我们算得的积分图 (先以行再以列). 第二个微分式表示在矩形四角的$\delta$函数. 等式右侧的点积运算就可以通过四个数组访问解决.
\subsection{Feature Discussion}
和可控过滤器 (steerable filter) (Freeman and Adelson, 1991; Greenspan et al., 1994) 等其他过滤器相比, 我们的矩形特征在某种程度上是比较原始的. 可控过滤器以及其他类似的擅长于边界分析, 图像压缩以及纹理分析. 
尽管矩形区域对边界, 条状物以及其他简单的图形结构有着较好的敏感度, 但是也是十分粗糙的. 不像那些可控过滤器, 矩形区域只有水平, 垂直, 对角三种排列方式. 因为正交性不是这个特征集合主要考虑的问题, 我们生成了数量巨大而多样的矩形特征. 这个数量已经远远过完备, 超过了所需数量将近400倍.
这个过完备的集合有着任意的纵横比以及精细的采样位置. 特别地, 它是一个能够有效学习的丰富的图像表示形式. 另外, 矩形区域计算的高效性极大地弥补了它的缺陷. 

为了对积分图技术带来的计算优势体会得更加深刻, 考虑计算金字塔状变化的图像序列时所用的传统方法. 就像大多数的面部识别系统, 我们的检测器扫描了图像的多种尺寸大小. 从基本尺寸$24\times24$像素开始, 一张$384\times288$像素大小的图像扫描了$12$种尺寸, 每一种都比前面一种大$1.25$倍.
传统方法和这个类似, 不过每次的尺寸都比前一次小$1.25$倍. 一个固定尺寸的检测器扫描了其中的每一张图像. 然而直接计算这个序列太耗费时间. 在传统机器上采用双线性插值算法 (bi-linear interpolation) 的高效实现, 计算$12$种尺寸仍然需要$0.05$秒 (Intel PIII 700MHz 处理器).

然而, 我们定义了一个矩形特征集, 其中的每一个特征只需要一点点操作便能从任何尺寸和位置上计算出来. 我们将在第四章节讲述如何使用两个矩形特征构造高效的面部检测器. 归功于计算特征的高效, 这个面部识别程序能够以每秒$15$帧的速度用一个尺寸完整地扫描整张图像.

\section{Learning Classification Functions}
只要有一个特征集, 正例反例图组成的训练集, 任何机器学习的算法就可以用来学习分类函数. Sung 和 Poggio 用了一个高斯混合模型 (Sung and Poggio, 1998). Rowley et al. (1998) 使用了一小部分图像特征集合以及神经网络. Osuna et al. (1997b) 使用了一个支持向量机. 最近 Roth et al. (2000) 公布了一个新型图像表现形式并使用了 Winnow 学习程序.

不得不提及的是和一个图片子区域相关的矩形特征有 $160000$个之多, 远远超过了像素的数量. 即使每个特征都能十分高效地计算, 计算那么多特征也是不切实际的. 根据我们实验后的结论, 只有一小部分的特征可以作为有效的分类器. 问题就在于如何找到这些特征.

我们使用 AdaBoost 算法的一个变体选取特征并训练分类器 (Freund and Schapire, 1995). 最初, AdaBoost 算法被用来提高简单学习算法的分类性能, 例如用来加速一个简单的感知器. 它通过联合多个弱分类函数形成一个更加强大的分类器. 在这一方面, 弱学习算法被称为弱学习器.
举个例子, 感知器学习算法从多个感知器中选择分类错误率最低的一个. 因为即使是最好的分类器效果也不是很好, 甚至对于特定问题只能达到 $51\%$的正确率, 所以它被称为弱学习器.
为了提高弱学习器的性能, 一系列学习问题有待解决. 第一轮的学习过后, 为了强调出被先前的弱分类器错误分类的那些样本, 权值必须重新标注. 最终的强分类器由一系列受权重和阈值约束的弱分类器组成.

AdaBoost 学习算法强有力地保证了我们结果地正确性. Freund 和 Schapire 证明强分类器的训练错误率随着训练轮数的增加以指数方式下降到$0$. 之后又出现了一些更加重要的成果 (Schapire et al., 1997). 其中的关键就是分类器的泛化性能和样本边界有关, 而 AdaBoost 算法能够很快达到那些边界.

传统的 AdaBoost 算法流程可以简单地视作贪心特征选取. 考虑一个一般性的问题. 很多分类函数通过加权多数表决的形式结合在一起, 那么如何将高权值分配给好的分类函数而将低权值分给差的分类函数呢? 
AdaBoost 算法有着一个良好的机制, 能够从低权值的分类器中选取一部分好分类器. 打个比方, 在弱分类器和特征之间, AdaBoost 算法能够高效地选取出一些好的特征, 可是好特征远不止这些.

完成这个类比的一个可行方法就是将弱学习器限制在只依赖单一特征的分类函数集中. 为了达到这个目标, 弱学习算法被设计成选取能够最优划分正反样本的单一矩形特征 (和 Tieu and Viola (2000) 在图像数据库领域达到的成就相似). 学习算法对每一个特征最优化阈函数 (threshold classification function), 例如最小化误分类样本数量. 一个弱分类器 $h(x,f,p,\theta)$ 包含了特征函数$f$, 阈值$\theta$以及代表了不确定方向的$p$:
\[
    h(x,f,p,\theta) =
    \begin{cases}
        1 &\quad\text{if}\quad pf(x)<p\theta \\
        0 &\quad\text{otherwise}
    \end{cases}
\]
公式中$x$表示图像的$24\times24$像素大小的子区域.

实际上没有一个单一特征能够小错误完成分类任务. 在程序早期的特征选取中错误率在$0.1-0.3$之间. 在后期随着任务变得不断困难, 特征选取的错误率在$0.4-0.5$之间. 下表中展示了该学习算法.
\begin{figure}[htb]
    \caption{一个能够在线查询学习的增强算法.$T$个假设使用单一特征构建. 最终的假设是$T$个假设的加权线性结合, 其中的权值和训练误差成反比}
    \begin{itemize}
        \item 由$n$个样例图$(x_1,y_1),\ldots,(x_n,y_n), y_i=0, 1$分别表示反例和正例.
        \item 初始化权值 $w_{1,i}=\frac{1}{2m}, \frac{1}{2l},y_i=0,1$其中$m$和$l$分别是反例和正例的数量.
        \item 对于每一个$t=1,\ldots,T$:
            \begin{enumerate}
                \item 规范化权值$w_{t,i}\leftarrow \frac{w_{t,i}}{\sum_{j=1}^n w_{t,j}}$
                \item 根据加权误差大小选取最好的弱分类器
                    \[
                        \epsilon_t=\min_{f,p,\theta}\sum_i{w_i| h(x_i,f,p,\theta)-y_i |}.
                    \]
                    查看章节对高效实现的讨论
                \item 定义函数$h_t(x)=h(x,f_t,p_t,\theta_t)$, 其中$f_t,p_t,\theta_t$是满足上式最小化$\epsilon_t$后的值
                \item 更新权值
                    \[
                        w_{t+1,i}=w_{t,i}\beta_t^{1-e_i}
                    \]
                    其中$e_i=0$仅当$x_i$被正确分类, 否则$e_i=1$. $\beta_t=\frac{\epsilon_t}{1-\epsilon_t}$.
            \end{enumerate}
        \item 最终的强分类器为
            \[
                C(x)=
                \begin{cases}
                    1 &\quad\sum\limits_{t=1}\limits^T \alpha_t h_t(x)\geq \frac12\sum\limits_{t=1}\limits^T\alpha_t\\
                    0 &\quad\text{otherwise}
                \end{cases}
            \]
    \end{itemize}
\end{figure}

我们使用的弱分类器 (带有阈值的单一特征) 可以看作是单一节点的决策树. 像这样子的结构在机器学习中称为单层决策树 (decision stump). Freund 和 Schapire (1995) 在最初也尝试过加速单层决策树.
\subsection{Learning Discussion}
在表中描述的算法用来从一组弱分类器中选取关键的弱分类器.尽管 AdaBoost 算法非常高效, 但是弱分类器的集合太大了. 一组特征/阈值对应着一个弱分类器, 若有$K$个特征以及$N$个样例, 则弱分类器就有$KN$个. 为了强调对$N$的依赖, 假设样例已经根据一个特定的特征值进行了排序. 考虑到训练过程, 被排序样例中相同对之间的阈值是等价的. 因此不同的阈值总数为$N$. 在一个$N=20000, K=160000$的任务中, 有$3.2\times 10^9$ 个弱分类器对.

这个封装方法也能够利用M个弱分类器学习出一个感知器 (John et al., 1994). 在每轮学习中, 这个方法将一个弱分类器添加至感知器中, 使得添加后的感知器错误率最低. 每轮训练的时间复杂度至少为$O(NKN)$ ($60$兆个操作). 每一轮中将遍历所有的特征对, 并用每一个特征评估每一个样例.
这个过程忽略了学习感知器权重的时间. 即使是这样, 学习$200$个特征的分类器的时间复杂度也大约是$O(MNKN)$, 差不多是$10^{16}$个操作.

作为特征选取算法, AdaBoost 的一个关键优势就在于学习速度. 使用 AdaBoost 算法后一个$200$个特征分类器可以在$O(MNK)$的时间或者大约$10^{11}$个操作内学习得到. 另一个关键优势在于每一轮学习中对前一个选取的特征的依赖性已经高校而完整的隐含在样例权重中, 利用这些权重能够在常数时间内评估一个给定的弱分类器.

弱分类器的选取算法如下. 对于每一个特征, 样例根据该特征的值进行排序. AdaBoost 最优阈值便能在单次遍历中计算得到. 对于其中的每一个元素, 我们计算和维护四个和:
\begin{itemize}
\item 正样例权重之和$T^+$
\item 反样例权重之和$T^-$
\item 小于当前样例的正样例权重之和$S^+$
\item 小于当前样例的反样例权重之和$S^-$
\end{itemize}
在已排序列表中, 分割当前样例和之前样例产生的误差为:
\[
e=\min(S^++(T^--S^^-),S^-+(T^+-S^+))
\]
将所有低于当前样本的标记为反样例, 将高于当前样本的标记为正样例, 或者相反. 取两种情况中的最小误差. 这些和在搜索的过程中很容易更新.

有很多的特征识别过程已经被提出 (参见 Webb (1999) 的第八章节). 我们最终的应用采取了一个非常激进的过程, 大量的特征被丢弃. 在一个相似的识别问题中,  Pagageorgiou et al. (1998) 基于特征差异
提出了一个特征选取的方法. 他们在总共 $1734$ 个特征中选取出$37$个特征, 取得了很好的结果. 尽管这已经是一个极大的简化措施, 但是对于每一个图像子区域待评估的特征数量还是太多.

Roth et al. (2000) 
\end{document}
